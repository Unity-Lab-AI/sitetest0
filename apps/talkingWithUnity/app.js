function logToScreen(message) {
    return;
}

/* =========================
   Debug Overlay (added)
   - Hidden by default
   - Toggle with ` or ~
   - Word wrap + scroll + capped lines
========================= */
(function ensureDebugOverlay() {
    return;
})();

// FIXED: make the debug banner reflect the real script path


// Initialize PolliLibJS API
const polliAPI = new PollinationsAPI();

const landingSection = document.getElementById('landing');
const appRoot = document.getElementById('app-root');
const heroStage = document.getElementById('hero-stage');
const heroImage = document.getElementById('hero-image');
const muteIndicator = document.getElementById('mute-indicator');
const indicatorText = muteIndicator?.querySelector('.indicator-text') ?? null;
const aiCircle = document.querySelector('[data-role="ai"]');
const userCircle = document.querySelector('[data-role="user"]');
const dependencyLight = document.querySelector('[data-role="dependency-light"]');
const dependencySummary = document.getElementById('dependency-summary');
const dependencyList = document.getElementById('dependency-list');
const launchButton = document.getElementById('launch-app');
const recheckButton = document.getElementById('recheck-dependencies');

if (heroImage) {
    heroImage.setAttribute('crossorigin', 'anonymous');
    heroImage.decoding = 'async';
}

const bodyElement = document.body;
if (bodyElement) {
    bodyElement.classList.remove('no-js');
    bodyElement.classList.add('js-enabled');
}

let currentImageModel = 'flux';
let chatHistory = [];
let systemPrompt = '';
let recognition = null;
let isMuted = true;
let hasMicPermission = false;
let currentHeroUrl = '';
let pendingHeroUrl = '';
let currentTheme = 'dark';
let recognitionRestartTimeout = null;
let recognitionPaused = false;
let appStarted = false;
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const synth = window.speechSynthesis;

const dependencyChecks = [
    {
        id: 'secure-context',
        label: 'Secure context (HTTPS or localhost)',
        check: () =>
            Boolean(window.isSecureContext) ||
            /^localhost$|^127(?:\.\d{1,3}){3}$|^[::1]$/.test(window.location.hostname)
    },
    {
        id: 'speech-recognition',
        label: 'Web Speech Recognition API',
        check: () => Boolean(SpeechRecognition)
    },
    {
        id: 'speech-synthesis',
        label: 'Speech synthesis voices',
        check: () => typeof synth !== 'undefined' && typeof synth.speak === 'function'
    },
    {
        id: 'microphone',
        label: 'Microphone access',
        check: () => Boolean(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
    }
];

if (heroStage && !heroStage.dataset.state) {
    heroStage.dataset.state = 'empty';
}

const currentScript = document.currentScript;
const directoryUrl = (() => {
    if (currentScript?.src) {
        try {
            return new URL('./', currentScript.src).toString();
        } catch (error) {
            console.error('Failed to derive directory from script src:', error);
        }
    }

    const href = window.location.href;
    const pathname = window.location.pathname || '';
    const lastSegment = pathname.substring(pathname.lastIndexOf('/') + 1);

    if (href.endsWith('/')) {
        return href;
    }

    if (lastSegment && lastSegment.includes('.')) {
        return href.substring(0, href.lastIndexOf('/') + 1);
    }

    return `${href}/`;
})();

function resolveAssetPath(relativePath) {
    try {
        return new URL(relativePath, directoryUrl).toString();
    } catch (error) {
        console.error('Failed to resolve asset path:', error);
        return relativePath;
    }
}

document.addEventListener('DOMContentLoaded', () => {
    evaluateDependencies();

    recheckButton?.addEventListener('click', () => {
        evaluateDependencies({ announce: true });
    });
});

window.addEventListener('focus', () => {
    if (!appStarted) {
        evaluateDependencies();
    }
});

function normalizeLaunchResults(detail) {
    if (!detail || typeof detail !== 'object') {
        return null;
    }

    const normalizedResults = Array.isArray(detail.results)
        ? detail.results
              .map((item) => {
                  if (!item || typeof item !== 'object') {
                      return null;
                  }

                  const id = typeof item.id === 'string' ? item.id : undefined;
                  if (!id) {
                      return null;
                  }

                  return {
                      id,
                      label: item.label || item.friendlyName || id,
                      met: Boolean(item.met)
                  };
              })
              .filter(Boolean)
        : null;

    if (!normalizedResults || normalizedResults.length === 0) {
        return null;
    }

    const inferredAllMet = normalizedResults.every((result) => result.met);
    const allMet = typeof detail.allMet === 'boolean' ? detail.allMet : inferredAllMet;

    return {
        results: normalizedResults,
        allMet
    };
}

async function handleTalkToUnityLaunch(detail) {
    logToScreen('handleTalkToUnityLaunch: Beginning execution');
    const normalized = normalizeLaunchResults(detail);

    if (normalized) {
        updateDependencyUI(normalized.results, normalized.allMet, { announce: false });
    } else if (!appStarted) {
        evaluateDependencies();
    }

    if (appStarted) {
        if (typeof window !== 'undefined') {
            delete window.__talkToUnityLaunchIntent;
        }
        logToScreen('handleTalkToUnityLaunch: Already started, exiting');
        return;
    }

    try {
        logToScreen('handleTalkToUnityLaunch: Starting application');
        await startApplication();
        logToScreen('handleTalkToUnityLaunch: Application started successfully');
    } catch (error) {
        console.error('Failed to start the Talk to Unity experience:', error);
        appStarted = false;
        throw error;
    } finally {
        if (typeof window !== 'undefined') {
            delete window.__talkToUnityLaunchIntent;
        }
    }
}

async function startApplication() {
    await ensureMicPermission();
    logToScreen('startApplication: Beginning execution');
    if (appStarted) {
        logToScreen('startApplication: Already started, exiting');
        return;
    }

    hasMicPermission = await ensureMicPermission();
    if (!hasMicPermission) {
        alert('Microphone permission is required to use the application.');
        return;
    }

    appStarted = true;

    console.log('startApplication: Before DOM manipulation. appRoot hidden:', appRoot?.hasAttribute('hidden'), 'landingSection aria-hidden:', landingSection?.getAttribute('aria-hidden'), 'body appState:', bodyElement?.dataset.appState);

    if (appRoot?.hasAttribute('hidden')) {
        logToScreen('startApplication: Showing app root');
        appRoot.removeAttribute('hidden');
    }

    if (bodyElement) {
        logToScreen('startApplication: Setting app state to experience');
        bodyElement.dataset.appState = 'experience';
    }

    if (landingSection) {
        logToScreen('startApplication: Hiding landing section');
        landingSection.setAttribute('aria-hidden', 'true');
    }

    console.log('startApplication: After DOM manipulation. appRoot hidden:', appRoot?.hasAttribute('hidden'), 'landingSection aria-hidden:', landingSection?.getAttribute('aria-hidden'), 'body appState:', bodyElement?.dataset.appState);

    if (heroStage) {
        if (!heroStage.dataset.state) {
            heroStage.dataset.state = 'idle';
        }
        heroStage.classList.add('is-visible');
    }

    applyTheme(currentTheme);
    await loadSystemPrompt();
    logToScreen('startApplication: Setting up speech recognition');
    await setupSpeechRecognition();
    logToScreen('startApplication: Speech recognition setup complete');
    updateMuteIndicator();
    await initializeVoiceControl();
    applyTheme(currentTheme, { force: true });
    await setMutedState(true, { announce: false });
    logToScreen('startApplication: Execution complete');
}
window.startApplication = startApplication;


async function setMutedState(muted, { announce = false } = {}) {
    if (!recognition) {
        isMuted = muted;
        updateMuteIndicator();
        if (muted) {
            setCircleState(userCircle, {
                listening: false,
                speaking: false,
                label: 'Microphone is muted'
            });
            if (announce) {
                speak('Microphone muted.');
            }
        } else {
            setCircleState(userCircle, {
                listening: true,
                label: 'Listening for your voice'
            });
            if (announce) {
                speak('Microphone unmuted.');
            }
        }
        return;
    }

    if (muted) {
        if (!isMuted) {
            isMuted = true;
            setCircleState(userCircle, {
                listening: false,
                speaking: false,
                label: 'Microphone is muted'
            });
            updateMuteIndicator();
            try {
                if (recognition) {
                    recognition.stop();
                }
            } catch (error) {
                console.error('Failed to stop recognition:', error);
            }
        } else {
            updateMuteIndicator();
        }

        if (announce) {
            speak('Microphone muted.');
        }

        return;
    }

    if (!hasMicPermission) {
        hasMicPermission = await requestMicPermission();
        if (!hasMicPermission) {
            updateMuteIndicator();
            if (announce) {
                speak('Microphone permission is required to unmute.');
            }
            return;
        }
    }

    if (!isMuted) {
        setCircleState(userCircle, {
            listening: true,
            label: 'Listening for your voice'
        });
        updateMuteIndicator();

        if (announce) {
            speak('Microphone is already listening.');
        }
        return;
    }

    isMuted = false;
    setCircleState(userCircle, {
        listening: true,
        label: 'Listening for your voice'
    });
    updateMuteIndicator();

    try {
        if (recognition) {
            recognition.start();
        }
    } catch (error) {
        console.error('Failed to start recognition:', error);
        setCircleState(userCircle, {
            error: true,
            listening: false,
            label: 'Unable to start microphone recognition'
        });
        isMuted = true;
        updateMuteIndicator();
        if (announce) {
            speak('Unable to start microphone recognition.');
        }
        return;
    }

    if (announce) {
        speak('Microphone unmuted.');
    }
}

function applyTheme(theme, { announce = false, force = false } = {}) {
    const normalizedTheme = theme === 'light' ? 'light' : 'dark';
    const body = document.body;
    const root = document.documentElement;

    if (!body) {
        currentTheme = normalizedTheme;
        if (root) {
            root.dataset.theme = normalizedTheme;
        }
        return;
    }

    const previousTheme = currentTheme;
    const wasThemeChanged =
        force ||
        previousTheme !== normalizedTheme ||
        body.dataset.theme !== normalizedTheme ||
        (root?.dataset.theme ?? previousTheme) !== normalizedTheme;

    currentTheme = normalizedTheme;
    body.dataset.theme = normalizedTheme;
    if (root) {
        root.dataset.theme = normalizedTheme;
    }

    if (announce) {
        if (!wasThemeChanged) {
            speak(normalizedTheme === 'light' ? 'Light theme is already active.' : 'Dark theme is already active.');
        } else {
            speak(normalizedTheme === 'light' ? 'Light theme activated.' : 'Dark theme activated.');
        }
    }
}

function setCircleState(circle, { speaking = false, listening = false, error = false, label = '' } = {}) {
    if (!circle) {
        return;
    }

    if (speaking) {
        if (circle.classList.contains('is-speaking')) {
            circle.classList.remove('is-speaking');
            void circle.offsetWidth;
        }
        circle.classList.add('is-speaking');
    } else {
        circle.classList.remove('is-speaking');
    }
    circle.classList.toggle('is-listening', listening);
    circle.classList.toggle('is-error', error);

    if (label) {
        circle.setAttribute('aria-label', label);
    }
}

async function loadSystemPrompt() {
    try {
        const response = await fetch(resolveAssetPath('ai-instruct.txt'));
        systemPrompt = await response.text();
    } catch (error) {
        console.error('Error fetching system prompt:', error);
        systemPrompt = 'You are Unity, a helpful AI assistant.';
    }
}

function loadScript(src) {
    return new Promise((resolve, reject) => {
        const script = document.createElement('script');
        const isAbsolute = /^https?:\/\//i.test(src);
        script.src = isAbsolute ? src : resolveAssetPath(src);
        script.onload = resolve;
        script.onerror = reject;
        document.head.appendChild(script);
    });
}

async function setupSpeechRecognition() {
    const hasPermission = await ensureMicPermission();
    if (!hasPermission) {
        console.warn('Microphone permission not granted, speech recognition will not be set up.');
        setCircleState(userCircle, { error: true, label: 'Microphone permission denied' });
        return;
    }

    const isFirefox = navigator.userAgent.toLowerCase().includes('firefox');

    if (isFirefox) {
        try {
            await loadScript('https://cdn.jsdelivr.net/npm/vosklet@0.2.1/dist/vosklet.umd.min.js');
            // FIXED: load adapter from the project root
            await loadScript('vosklet-adapter.js');
            recognition = await createVoskletRecognizer(
                (event) => { // onresult
                    if (recognitionPaused) return;
                    const transcript = event.results[event.results.length - 1][0].transcript.trim();
                    console.log('User said (Vosklet):', transcript);
                    setCircleState(userCircle, { listening: true, speaking: false, label: 'Processing what you said' });
                    const isLocalCommand = handleVoiceCommand(transcript);
                    if (!isLocalCommand) {
                        getAIResponse(transcript);
                    }
                },
                (event) => { // onerror
                    console.error('Vosklet recognition error:', event.error);
                    setCircleState(userCircle, { error: true, listening: false, speaking: false, label: `Microphone error: ${event.error}` });
                }
            );
        } catch (error) {
            console.error('Failed to load Vosklet:', error);
            alert('Failed to load speech recognition module for Firefox.');
            setCircleState(userCircle, { label: 'Speech recognition module failed to load', error: true });
            return;
        }
    } else if (SpeechRecognition) {
        try {
            recognition = new SpeechRecognition();
        } catch (error) {
            console.error('Failed to create SpeechRecognition instance:', error);
            alert('Failed to initialize speech recognition. Please check your browser settings and permissions.');
            setCircleState(userCircle, { label: 'Speech recognition failed to initialize', error: true });
            return;
        }
        recognition.continuous = true;
        recognition.lang = 'en-US';
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        recognition.onresult = (event) => {
            if (recognitionPaused) return;
            const transcript = event.results[event.results.length - 1][0].transcript.trim();
            console.log('User said:', transcript);
            setCircleState(userCircle, { listening: true, speaking: false, label: 'Processing what you said' });
            const isLocalCommand = handleVoiceCommand(transcript);
            if (!isLocalCommand) {
                getAIResponse(transcript);
            }
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            setCircleState(userCircle, { error: true, listening: false, speaking: false, label: `Microphone error: ${event.error}` });
        };
    } else {
        console.error('Speech recognition is not supported in this browser.');
        alert('Speech recognition is not supported in this browser.');
        setCircleState(userCircle, { label: 'Speech recognition is not supported in this browser', error: true });
        return;
    }

    recognition.onstart = () => {
        console.log('Voice recognition started.');
        setCircleState(userCircle, { listening: true, label: 'Listening for your voice' });
    };

    recognition.onaudiostart = () => {
        setCircleState(userCircle, { listening: true, label: 'Listening for your voice' });
    };

    recognition.onspeechstart = () => {
        setCircleState(userCircle, { speaking: true, listening: true, label: 'Hearing you speak' });
    };

    recognition.onspeechend = () => {
        setCircleState(userCircle, { listening: true, speaking: false, label: 'Processing what you said' });
    };

    recognition.onend = () => {
        console.log('Voice recognition stopped.');
        setCircleState(userCircle, { listening: false, speaking: false, label: isMuted ? 'Microphone is muted' : 'Listening for your voice' });
    };
}

async function initializeVoiceControl() {
    if (!recognition) {
        return;
    }

    hasMicPermission = await ensureMicPermission();
    if (!hasMicPermission) {
        alert('Microphone access is required for voice control.');
        updateMuteIndicator();
        return;
    }
}

async function requestMicPermission() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('Microphone access is not supported in this browser.');
        setCircleState(userCircle, {
            error: true,
            label: 'Microphone access is not supported in this browser'
        });
        return false;
    }

    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // stream.getTracks().forEach((track) => track.stop());
        setCircleState(userCircle, {
            label: 'Microphone is muted'
        });
        localStorage.setItem('micPermission', 'granted');
        hasMicPermission = true;
        return true;
    } catch (error) {
        console.error('Microphone permission denied:', error);
        setCircleState(userCircle, {
            error: true,
            label: 'Microphone permission denied'
        });
        return false;
    }
}

function updateMuteIndicator() {
    if (!muteIndicator) {
        return;
    }

    muteIndicator.classList.add('is-visible');
    muteIndicator.setAttribute('aria-hidden', 'false');

    if (isMuted) {
        const message = hasMicPermission
            ? 'Tap or click anywhere to unmute'
            : 'Tap or click anywhere to start';
        indicatorText && (indicatorText.textContent = message);
        muteIndicator.dataset.state = 'muted';
        muteIndicator.setAttribute('aria-label', 'Microphone muted. Tap to enable listening.');
    } else if (recognitionPaused) {
        indicatorText && (indicatorText.textContent = 'Mic ignored');
        muteIndicator.dataset.state = 'muted';
        muteIndicator.setAttribute('aria-label', 'Microphone ignored while AI is responding.');
    } else {
        indicatorText && (indicatorText.textContent = 'Listening… tap to mute');
        muteIndicator.dataset.state = 'listening';
        muteIndicator.setAttribute('aria-label', 'Microphone active. Tap to mute.');
    }
}

async function attemptUnmute() {
    const permission = await ensureMicPermission();
    if (permission) {
        await setMutedState(false);
    }
}

function handleMuteToggle(event) {
    event?.stopPropagation();

    if (isMuted) {
        attemptUnmute();
        return;
    }

    setMutedState(true);
}

muteIndicator?.addEventListener('click', handleMuteToggle);

document.addEventListener('click', () => {
    if (isMuted) {
        attemptUnmute();
    }
});

document.addEventListener('keydown', (event) => {
    if ((event.key === 'Enter' || event.key === ' ') && isMuted) {
        event.preventDefault();
        attemptUnmute();
    }
});


function isLikelyUrlSegment(segment) {
    if (typeof segment !== 'string' || segment.trim() === '') {
        return false;
    }

    const cleaned = segment
        .replace(/^[<({\[\s'"“”‘’`]+/g, '')
        .replace(/[>)}\]\s'"“”‘’`]+$/g, '')
        .replace(/[.,!?;:]+$/g, '')
        .trim();

    if (cleaned === '') {
        return false;
    }

    const normalized = cleaned.toLowerCase();

    if (
        normalized.startsWith('http://') ||
        normalized.startsWith('https://') ||
        normalized.startsWith('www.') ||
        normalized.includes('://')
    ) {
        return true;
    }

    if (/^[a-z0-9.-]+\.[a-z]{2,}(?:[/?#].*)?$/.test(normalized)) {
        return true;
    }

    return false;
}

function removeMarkdownLinkTargets(value) {
    return value
        .replace(/!\[([^\]]*)\]\(([^)]+)\)/g, (_match, altText, url) => {
            return isLikelyUrlSegment(url) ? altText : _match;
        })
        .replace(/\ \[\[^\]]*\]\(([^)]+)\)/g, (_match, linkText, url) => {
            return isLikelyUrlSegment(url) ? linkText : _match;
        })
        .replace(/\ \[\[ (?:command|action)[^\\]*\]\([^)]*\)\]/gi, ' ');
}

function removeCommandArtifacts(value) {
    if (typeof value !== 'string') {
        return '';
    }

    let result = value
        .replace(/\ \[\[ [^\\]*\bcommand\b[^\\]*\]/gi, ' ')
        .replace(/\([^)]*\bcommand\b[^)]*\)/gi, ' ')
        .replace(/<[^>]*\bcommand\b[^>]*>/gi, ' ')
        .replace(/\bcommands?\s*[:=-]\s*[a-z0-9_\s-]+/gi, ' ')
        .replace(/\bactions?\s*[:=-]\s*[a-z0-9_\s-]+/gi, ' ')
        .replace(/\b(?:execute|run)\s+command\s*(?:[:=-]\s*)?[a-z0-9_-]*/gi, ' ')
        .replace(/\bcommand\s*(?:[:=-]\s*|\s+)(?:[a-z0-9_-]+(?:\s+[a-z0-9_-]+)*)?/gi, ' ');

    result = result.replace(/^\s*[-*]?\s*(?:command|action)[^\n]*$/gim, ' ');

    return result;
}

function sanitizeForSpeech(text) {
    if (typeof text !== 'string') {
        return '';
    }

    const withoutDirectives = text
        .replace(/\ \[\[command:[^\\]*\]/gi, ' ')
        .replace(/\{command:[^}]*\}/gi, ' ')
        .replace(/<command[^>]*>[^<]*<\/command>/gi, ' ')
        .replace(/\\b(?:command|action)\\s*[:=]\\s*([a-z0-9_\\-]+)/gi, ' ')
        .replace(/\\bcommands?\s*[:=]\\s*([a-z0-9_\\-]+)/gi, ' ')
        .replace(/\\b(?:command|action)\\s*(?:->|=>|::)\\s*([a-z0-9_\\-]+)/gi, ' ')
        .replace(/\\bcommand\\s*\([^)]*\)/gi, ' ');

    const withoutPollinations = withoutDirectives
        .replace(/https?:\/\/\S*images?\.pollinations\.ai\S*/gi, '')
        .replace(/\b\S*images?\.pollinations\.ai\S*\b/gi, '');

    const withoutMarkdownTargets = removeMarkdownLinkTargets(withoutPollinations);
    const withoutCommands = removeCommandArtifacts(withoutMarkdownTargets);

    const withoutGenericUrls = withoutCommands
        .replace(/https?:\/\/\S+/gi, ' ')
        .replace(/\bwww\.[^\s)]+/gi, ' ');

    const withoutSpacedUrls = withoutGenericUrls
        .replace(/h\s*t\s*t\s*p\s*s?\s*:\s*\/\/\s*[\w\-./?%#&=]+/gi, ' ')
        .replace(/\bhttps?\b/gi, ' ')
        .replace(/\bwww\b/gi, ' ');

    const withoutSpelledUrls = withoutSpacedUrls
        .replace(/h\s*t\s*t\s*p\s*s?\s*(?:[:=]|colon)\s*\/\/\s*[\w\-./?%#&=]+/gi, ' ')
        .replace(/\b(?:h\s*t\s*t\s*p\s*s?|h\s*t\s*t\s*p)\b/gi, ' ')
        .replace(/\bcolon\b/gi, ' ')
        .replace(/\bslash\b/gi, ' ');

    const parts = withoutSpelledUrls.split(/(\s+)/);
    const sanitizedParts = parts.map((part) => {
        if (isLikelyUrlSegment(part)) {
            return '';
        }

        if (/(?:https?|www|:\/\/|\.com|\.net|\.org|\.io|\.ai|\.co|\.gov|\.edu)/i.test(part)) {
            return '';
        }

        if (/\bcommand\b/i.test(part)) {
            return '';
        }

        if (/(?:image|artwork|photo)\s+(?:url|link)/i.test(part)) {
            return '';
        }

        return part;
    });

    const commandTokens = [
        'open_image',
        'save_image',
        'copy_image',
        'mute_microphone',
        'unmute_microphone',
        'stop_speaking',
        'shutup',
        'set_model_flux',
        'set_model_turbo',
        'set_model_kontext',
        'clear_chat_history',
        'theme_light',
        'theme_dark'
    ];

    let sanitized = sanitizedParts
        .join('')
        .replace(/\s{2,}/g, ' ')
        .replace(/\s+([.,!?;:])/g, '$1')
        .replace(/\(\s*\)/g, '')
        .replace(/\[\s*\]/g, '')
        .replace(/\{\s*\}/g, '')
        .replace(/\b(?:https?|www)\b/gi, '')
        .replace(/\b[a-z0-9]+\s+dot\s+[a-z0-9]+\b/gi, '')
        .replace(/\b(?:dot\s+)(?:com|net|org|io|ai|co|gov|edu|xyz)\b/gi, '')

        .replace(/<\s*>/g, '')
        .replace(/\bcommand\b/gi, '')
        .replace(/\b(?:image|artwork|photo)\s+(?:url|link)\b.*$/gim, '')
        .trim();

    return sanitized;
}

function cutImageUrl(url) {
    if (!url) {
        return '';
    }
    const parts = url.split('?');
    return parts[0];
}

function sanitizeImageUrl(rawUrl) {
    if (typeof rawUrl !== 'string') {
        return '';
    }

    return rawUrl
        .trim()
        .replace(/^["'<\\\\[({]+/g, '')
        .replace(/["'>)\]}]+$/g, '')
        .replace(/[,.;!]+$/g, '');
}

const FALLBACK_IMAGE_KEYWORDS = [
    'show',
    'picture',
    'image',
    'photo',
    'illustration',
    'draw',
    'paint',
    'render',
    'display',
    'visual',
    'wallpaper',
    'generate'
];

function shouldRequestFallbackImage({ userInput = '', assistantMessage = '', fallbackPrompt = '', existingImageUrl = '' }) {
    if (existingImageUrl || !fallbackPrompt) {
        return false;
    }

    const combined = `${userInput} ${assistantMessage}`.toLowerCase();
    if (combined.includes('[image]')) {
        return true;
    }

    const keywordPattern = new RegExp(`\\b(?:${FALLBACK_IMAGE_KEYWORDS.join('|')})\\b`, 'i');
    if (keywordPattern.test(combined)) {
        return true;
    }

    const descriptiveCuePattern = /(here\s+(?:is|'s)|displaying|showing)\\s+(?:an?\s+)?(?:image|picture|photo|visual)/i;
    return descriptiveCuePattern.test(combined);
}

function cleanFallbackPrompt(text) {
    return text
        .replace(/^["\'​\s]+/g, '')
        .replace(/["\'​\s]+$/g, '')
        .replace(/\s{2,}/g, ' ')
        .trim();
}

function buildFallbackImagePrompt(userInput = '', assistantMessage = '') {
    const sources = [assistantMessage, userInput];
    for (const source of sources) {
        if (!source) {
            continue;
        }

        const explicitPromptMatch = source.match(/(?:image\s+prompt|prompt)\s*[:=]\s*"?([^"\n]+)"?/i);
        if (explicitPromptMatch?.[1]) {
            const sanitized = cleanFallbackPrompt(explicitPromptMatch[1]);
            if (sanitized) {
                return sanitized;
            }
        }
    }

    const rawCandidate = userInput || assistantMessage || '';
    if (!rawCandidate) {
        return '';
    }

    const cleaned = cleanFallbackPrompt(
        rawCandidate
            .replace(/\\b(?:please|kindly)\\b/gi, '')
            .replace(/\\b(?:can|could|would|will|may|might|let's)\\b\\s+(?:you\\s+)?/gi, '')
            .replace(
                /\\b(?:show|display|draw|paint|generate|create|make|produce|render|give|find|display)\\b\\s+(?:me\\s+|us\\s+)?/gi,
                ''
            )
            .replace(
                /\\b(?:an?\s+)?(?:image|picture|photo|visual|illustration|render|drawing|art|shot|wallpaper)\\b\\s*(?:of|showing)?\\s*/gi,
                ''
            )
    );

    if (!cleaned) {
        return '';
    }

    return cleaned.charAt(0).toUpperCase() + cleaned.slice(1);
}

function buildPollinationsImageUrl(prompt, { model = currentImageModel } = {}) {
    if (typeof prompt !== 'string') {
        return '';
    }

    const sanitized = cleanFallbackPrompt(prompt);
    if (!sanitized) {
        return '';
    }

    const params = new URLSearchParams({
        model: model || 'flux',
        width: '1024',
        height: '1024',
        nologo: 'true',
        enhance: 'true',
        seed: Math.floor(Math.random() * 1_000_000_000).toString(),
        referrer: encodeURIComponent(polliAPI.referrer)
    });

    return `${PollinationsAPI.IMAGE_API}/prompt/${polliAPI.encodePrompt(sanitized)}?${params.toString()}`;
}

function extractImageUrl(text) {
    if (typeof text !== 'string' || text.trim() === '') {
        return '';
    }

    const markdownMatch = text.match(/!\[[^\]]*\]\((https?:\/\/[^)\s]+)\)/i);
    if (markdownMatch && markdownMatch[1]) {
        return sanitizeImageUrl(markdownMatch[1]);
    }

    const urlMatch = text.match(/https?:\/\/[^)\s]+/i);
    if (urlMatch && urlMatch[0]) {
        return sanitizeImageUrl(urlMatch[0]);
    }

    return '';
}

function escapeRegExp(value) {
    return value.replace(/[-/\\^$*+?.()|[\\]{}]/g, '\\$&');
}

function removeImageReferences(text, imageUrl) {
    if (typeof text !== 'string') {
        return '';
    }

    if (!imageUrl) {
        return text.trim();
    }

    const sanitizedUrl = sanitizeImageUrl(imageUrl);
    if (!sanitizedUrl) {
        return text.trim();
    }

    let result = text;
    const escapedUrl = escapeRegExp(sanitizedUrl);

    const markdownImageRegex = new RegExp(`!\[[^\]]*\]\(${escapedUrl}\)`, 'gi');
    result = result.replace(markdownImageRegex, '');

    const markdownLinkRegex = new RegExp(`\[[^\]]*\]\(${escapedUrl}\)`, 'gi');
    result = result.replace(markdownLinkRegex, '');

    const rawUrlRegex = new RegExp(escapedUrl, 'gi');
    result = result.replace(rawUrlRegex, '');

    result = result
        .replace(/\\bimage\\s+url\\s*:?/gi, '')
        .replace(/\\bimage\\s+link\\s*:?/gi, '')
        .replace(/\\bart(?:work)?\\s+(?:url|link)\\s*:?/gi, '')
        .replace(/<\s*>/g, '')
        .replace(/\(\s*\)/g, '')
        .replace(/\\\[\\s*\]/g, '');

    return result
        .replace(/\\n{3,}/g, '\\n\\n')
        .replace(/[ \t]{2,}/g, ' ')
        .replace(/\\s+([.,!?;:])/g, '$1')
        .trim();
}

function normalizeCommandValue(value) {
    return value.replace(/[\s-]+/g, '_').trim().toLowerCase();
}

function parseAiDirectives(responseText) {
    if (typeof responseText !== 'string' || responseText.trim() === '') {
        return { cleanedText: '', commands: [] };
    }

    const commands = [];
    let workingText = responseText;

    const patterns = [
        /\ \[\[command:\s*([^\\]+)\]/gi,
        /\{command:\s*([^}]*)\}/gi,
        /<command[^>]*>\s*([^<]*)<\/command>/gi,
        /\\bcommand\\s*[:=]\s*([a-z0-9_\\-]+)/gi,
        /\\bcommands?\s*[:=]\s*([a-z0-9_\\-]+)/gi,
        /\\baction\s*[:=]\s*([a-z0-9_\\-]+)/gi,
        /\\b(?:command|action)\\s*(?:->|=>|::)\\s*([a-z0-9_\\-]+)/gi,
        /\\bcommand\\s*\(\s*([^)]+?)\s*\)/gi
    ];

    for (const pattern of patterns) {
        workingText = workingText.replace(pattern, (_match, commandValue) => {
            if (commandValue) {
                const normalized = normalizeCommandValue(commandValue);
                if (normalized) {
                    commands.push(normalized);
                }
            }
            return ' ';
        });
    }

    const slashCommandRegex = /(?:^|\s)\/ (open_image|save_image|copy_image|mute_microphone|unmute_microphone|stop_speaking|shutup|set_model_flux|set_model_turbo|set_model_kontext|clear_chat_history|theme_light|theme_dark)\\b/gi;
    workingText = workingText.replace(slashCommandRegex, (_match, commandValue) => {
        const normalized = normalizeCommandValue(commandValue);
        if (normalized) {
            commands.push(normalized);
        }
        return ' ';
    });

    const directiveBlockRegex = /(?:^|\\n)\\s*(?:commands?|actions?)\\s*:?\\s*(?:\\n|$ )((?:\\s*[-*•]?\\s*[a-z0-9_\\-]+\\s*(?:\\(\\))?\\s*(?:\\n|$))+)/gi;
    workingText = workingText.replace(directiveBlockRegex, (_match, blockContent) => {
        const lines = blockContent
            .split(/\\n+/) // Split by one or more newlines
            .map((line) => line.replace(/^[^a-z0-9]+/i, '').trim())
            .filter(Boolean);

        for (const line of lines) {
            const normalized = normalizeCommandValue(line.replace(/\(\)/g, ''));
            if (normalized) {
                commands.push(normalized);
            }
        }

        return '\\n';
    });

    const cleanedText = workingText.replace(/\\n{3,}/g, '\\n\\n').trim();
    const uniqueCommands = [...new Set(commands)];

    return { cleanedText, commands: uniqueCommands };
}

async function executeAiCommand(command, options = {}) {
    if (!command) {
        return false;
    }

    const normalized = normalizeCommandValue(command);

    switch (normalized) {
        case 'mute_microphone':
            await setMutedState(true, { announce: true });
            return true;
        case 'unmute_microphone':
            await setMutedState(false, { announce: true });
            return true;
        case 'stop_speaking':
        case 'shutup':
            synth.cancel();
            setCircleState(aiCircle, {
                speaking: false,
                label: 'Unity is idle'
            });
            return true;
        case 'copy_image':
            await copyImageToClipboard(options.imageUrl);
            return true;
        case 'save_image':
            await saveImage(options.imageUrl);
            return true;
        case 'open_image':
            openImageInNewTab(options.imageUrl);
            return true;
        case 'set_model_flux':
            currentImageModel = 'flux';
            speak('Image model set to flux.');
            return true;
        case 'set_model_turbo':
            currentImageModel = 'turbo';
            speak('Image model set to turbo.');
            return true;
        case 'set_model_kontext':
            currentImageModel = 'kontext';
            speak('Image model set to kontext.');
            return true;
        case 'clear_chat_history':
            chatHistory = [];
            speak('Chat history cleared.');
            return true;
        case 'theme_light':
            applyTheme('light', { announce: true });
            return true;
        case 'theme_dark':
            applyTheme('dark', { announce: true });
            return true;
        default:
            return false;
    }
}

function speak(text) {
    return new Promise((resolve) => {
        if (synth.speaking) {
            synth.cancel();
        }

        const sanitizedText = sanitizeForSpeech(text);

        if (sanitizedText === '') {
            resolve();
            return;
        }

        const utterance = new SpeechSynthesisUtterance(sanitizedText);
        const voices = synth.getVoices();
        const ukFemaleVoice = voices.find(
            (voice) => voice.name.includes('Google UK English Female') || (voice.lang === 'en-GB' && voice.gender === 'female')
        );

        if (ukFemaleVoice) {
            utterance.voice = ukFemaleVoice;
        } else {
            console.warn('UK English female voice not found, using default.');
        }

        utterance.onstart = () => {
            console.log('AI is speaking...');
            recognitionPaused = true;
            updateMuteIndicator();
            setCircleState(aiCircle, {
                speaking: true,
                label: 'Unity is speaking'
            });
        };

        utterance.onend = () => {
            console.log('AI finished speaking.');
            setCircleState(aiCircle, {
                speaking: false,
                label: 'Unity is idle'
            });
            resolve();
        };

        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event.error);
            setCircleState(aiCircle, {
                speaking: false,
                label: 'Unity is idle',
                error: true
            });
            resolve(); // Resolve anyway to not block the flow
        };

        synth.speak(utterance);
    });
}


function handleVoiceCommand(command) {
    const lowerCaseCommand = command.toLowerCase();

    if (
        lowerCaseCommand.includes('mute my mic') ||
        lowerCaseCommand.includes('mute microphone') ||
        lowerCaseCommand === 'mute'
    ) {
        setMutedState(true, { announce: true });
        return true;
    }

    if (
        lowerCaseCommand.includes('unmute my mic') ||
        lowerCaseCommand.includes('unmute microphone') ||
        lowerCaseCommand.includes('turn on the mic') ||
        lowerCaseCommand === 'unmute'
    ) {
        setMutedState(false, { announce: true });
        return true;
    }

    if (lowerCaseCommand.includes('shut up') || lowerCaseCommand.includes('be quiet')) {
        synth.cancel();
        setCircleState(aiCircle, {
            speaking: false,
            label: 'Unity is idle'
        });
        return true;
    }

    if (
        lowerCaseCommand.includes('light mode') ||
        lowerCaseCommand.includes('light theme') ||
        lowerCaseCommand.includes('day mode')
    ) {
        applyTheme('light', { announce: true });
        return true;
    }

    if (
        lowerCaseCommand.includes('dark mode') ||
        lowerCaseCommand.includes('dark theme') ||
        lowerCaseCommand.includes('night mode')
    ) {
        applyTheme('dark', { announce: true });
        return true;
    }

    if (lowerCaseCommand.includes('copy image') || lowerCaseCommand.includes('copy this image')) {
        copyImageToClipboard();
        return true;
    }

    if (lowerCaseCommand.includes('save image') || lowerCaseCommand.includes('download image')) {
        saveImage();
        return true;
    }

    if (lowerCaseCommand.includes('open image') || lowerCaseCommand.includes('open this image')) {
        openImageInNewTab();
        return true;
    }

    if (lowerCaseCommand.includes('use flux model') || lowerCaseCommand.includes('switch to flux')) {
        currentImageModel = 'flux';
        speak('Image model set to flux.');
        return true;
    }

    if (lowerCaseCommand.includes('use turbo model') || lowerCaseCommand.includes('switch to turbo')) {
        currentImageModel = 'turbo';
        speak('Image model set to turbo.');
        return true;
    }

    if (lowerCaseCommand.includes('use kontext model') || lowerCaseCommand.includes('switch to kontext')) {
        currentImageModel = 'kontext';
        speak('Image model set to kontext.');
        return true;
    }

    if (
        lowerCaseCommand.includes('clear history') ||
        lowerCaseCommand.includes('delete history') ||
        lowerCaseCommand.includes('clear chat') ||
        lowerCaseCommand.includes('clear chat history')
    ) {
        chatHistory = [];
        speak('Chat history cleared.');
        return true;
    }

    if (
        lowerCaseCommand.includes('light mode') ||
        lowerCaseCommand.includes('light theme') ||
        lowerCaseCommand.includes('change to light') ||
        lowerCaseCommand.includes('switch to light') ||
        lowerCaseCommand.includes('change them to light')
    ) {
        const wasUpdated = currentTheme !== 'light';
        applyTheme('light');
        speak(wasUpdated ? 'Switched to the light theme.' : 'Light theme is already active.');
        return true;
    }

    if (
        lowerCaseCommand.includes('dark mode') ||
        lowerCaseCommand.includes('dark theme') ||
        lowerCaseCommand.includes('change to dark') ||
        lowerCaseCommand.includes('switch to dark') ||
        lowerCaseCommand.includes('change them to dark')
    ) {
        const wasUpdated = currentTheme !== 'dark';
        applyTheme('dark');
        speak(wasUpdated ? 'Switched to the dark theme.' : 'Dark theme is already active.');
        return true;
    }

    return false;
}

const POLLINATIONS_TEXT_URL = PollinationsAPI.TEXT_API;
const UNITY_REFERRER = 'https://www.unityailab.com/';

async function getAIResponse(userInput) {
    recognitionPaused = true;
    updateMuteIndicator();

    try {
        console.log(`Sending to AI: ${userInput}`);

        chatHistory.push({ role: 'user', content: userInput });

        if (chatHistory.length > 12) {
            chatHistory.splice(0, chatHistory.length - 12);
        }

        let aiText = '';

        const messages = [{ role: 'system', content: systemPrompt }, ...chatHistory];

        const pollinationsPayload = JSON.stringify({
            messages,
            model: 'unity'
        });

        const textResponse = await polliAPI.retryRequest(POLLINATIONS_TEXT_URL, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            // Explicitly identify the Unity AI Lab referrer so the public
            // Pollinations endpoint treats the request as coming from the
            // approved web client even when running the app from localhost.
            referrer: UNITY_REFERRER,
            referrerPolicy: 'strict-origin-when-cross-origin',
            body: pollinationsPayload
        });

        if (!textResponse.ok) {
            throw new Error(`Pollinations text API returned ${textResponse.status}`);
        }

        const data = await textResponse.json();
        aiText = data.choices?.[0]?.message?.content ?? '';

        if (!aiText) {
            throw new Error('Received empty response from Pollinations AI');
        }

        const { cleanedText, commands } = parseAiDirectives(aiText);
        const assistantMessage = cleanedText || aiText;
        const imageUrlFromResponse = cutImageUrl(extractImageUrl(aiText) || extractImageUrl(assistantMessage));

        const imageCommandQueue = [];
        for (const command of commands) {
            const normalizedCommand = normalizeCommandValue(command);
            if (['copy_image', 'save_image', 'open_image'].includes(normalizedCommand)) {
                imageCommandQueue.push(normalizedCommand);
                continue;
            }

            await executeAiCommand(normalizedCommand);
        }

        const fallbackPrompt = buildFallbackImagePrompt(userInput, assistantMessage);
        let fallbackImageUrl = '';
        if (
            shouldRequestFallbackImage({
                userInput,
                assistantMessage,
                fallbackPrompt,
                existingImageUrl: imageUrlFromResponse
            })
        ) {
            fallbackImageUrl = buildPollinationsImageUrl(fallbackPrompt, { model: currentImageModel });
        }

        const selectedImageUrl = imageUrlFromResponse || fallbackImageUrl;

        const assistantMessageWithoutImage = selectedImageUrl
            ? removeImageReferences(assistantMessage, selectedImageUrl)
            : assistantMessage;

        const finalAssistantMessage = assistantMessageWithoutImage.replace(/\n{3,}/g, '\n\n').trim();
        const chatAssistantMessage = finalAssistantMessage || '[image]';

        chatHistory.push({ role: 'assistant', content: chatAssistantMessage });

        let heroImagePromise = Promise.resolve(false);
        if (selectedImageUrl) {
            heroImagePromise = updateHeroImage(selectedImageUrl);
        }

        const shouldSuppressSpeech = commands.includes('shutup') || commands.includes('stop_speaking');

        if (imageCommandQueue.length > 0) {
            await heroImagePromise;
            const imageTarget = selectedImageUrl || getImageUrl() || pendingHeroUrl;
            for (const command of imageCommandQueue) {
                await executeAiCommand(command, { imageUrl: imageTarget });
            }
        }

        if (!shouldSuppressSpeech) {
            const spokenText = sanitizeForSpeech(finalAssistantMessage);
            if (spokenText) {
                await heroImagePromise;
                await speak(spokenText);
            }
        }

        return {
            text: finalAssistantMessage,
            rawText: aiText,
            imageUrl: selectedImageUrl,
            commands
        };
    } catch (error) {
        console.error('Error getting text from Pollinations AI:', error);
        setCircleState(aiCircle, {
            error: true,
            label: 'Unity could not respond'
        });
        await speak("Sorry, I couldn't get a text response.");
        setTimeout(() => {
            setCircleState(aiCircle, {
                error: false,
                label: 'Unity is idle'
            });
        }, 2400);

        return { error };
    } finally {
        recognitionPaused = false;
        updateMuteIndicator();
    }
}

function getImageUrl() {
    if (currentHeroUrl) {
        return currentHeroUrl;
    }

    if (heroImage?.getAttribute('src')) {
        return heroImage.getAttribute('src');
    }

    return '';
}

function updateHeroImage(imageUrl) {
    if (!heroStage || !heroImage || !imageUrl) {
        return Promise.resolve(false);
    }

    heroStage.classList.add('is-visible');

    if (imageUrl === currentHeroUrl && heroStage.dataset.state === 'loaded') {
        heroStage.setAttribute('aria-hidden', heroStage.classList.contains('has-image') ? 'false' : 'true');
        return Promise.resolve(true);
    }

    heroStage.setAttribute('aria-hidden', 'true');

    const hadImage = heroStage.classList.contains('has-image');

    pendingHeroUrl = imageUrl;
    heroStage.dataset.state = 'loading';
    if (!hadImage) {
        heroStage.classList.remove('has-image');
        heroImage.removeAttribute('src');
    }

    return new Promise((resolve) => {
        const image = new Image();
        image.decoding = 'async';
        image.crossOrigin = 'anonymous';

        image.onload = () => {
            if (pendingHeroUrl !== imageUrl) {
                resolve(false);
                return;
            }

            currentHeroUrl = imageUrl;
            pendingHeroUrl = '';
            heroImage.src = imageUrl;
            heroStage.dataset.state = 'loaded';
            heroStage.classList.add('has-image');
            heroStage.setAttribute('aria-hidden', 'false');
            resolve(true);
        };

        image.onerror = (error) => {
            if (pendingHeroUrl === imageUrl) {
                pendingHeroUrl = '';
            }
            if (!hadImage) {
                heroStage.dataset.state = 'error';
                heroStage.classList.remove('has-image');
                heroImage.removeAttribute('src');
                heroStage.setAttribute('aria-hidden', 'true');
            } else {
                heroStage.dataset.state = 'loaded';
                heroStage.setAttribute('aria-hidden', 'false');
            }
            console.error('Failed to load hero image:', error);
            resolve(false);
        };

        image.src = imageUrl;
    });
}

async function copyImageToClipboard(imageUrlOverride) {
    const imageUrl = imageUrlOverride || getImageUrl() || pendingHeroUrl;
    if (!imageUrl) {
        return;
    }

    try {
        const response = await fetch(imageUrl);
        const blob = await response.blob();
        await navigator.clipboard.write([new ClipboardItem({ [blob.type]: blob })]);
        speak('Image copied to clipboard.');
    } catch (error) {
        console.error('Failed to copy image: ', error);
        speak('Sorry, I could not copy the image. This might be due to browser limitations.');
    }
}

async function saveImage(imageUrlOverride) {
    const imageUrl = imageUrlOverride || getImageUrl() || pendingHeroUrl;
    if (!imageUrl) {
        return;
    }

    try {
        const response = await fetch(imageUrl);
        const blob = await response.blob();
        const url = window.URL.createObjectURL(blob);
        const link = document.createElement('a');
        link.style.display = 'none';
        link.href = url;
        link.download = 'pollination_image.png';
        document.body.appendChild(link);
        link.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(link);
        speak('Image saved.');
    } catch (error) {
        console.error('Failed to save image: ', error);
        speak('Sorry, I could not save the image.');
    }
}

function openImageInNewTab(imageUrlOverride) {
    const imageUrl = imageUrlOverride || getImageUrl() || pendingHeroUrl;
    if (!imageUrl) {
        return;
    }

    window.open(imageUrl, '_blank');
    speak('Image opened in new tab.');
}

if (!launchButton && !landingSection) {
    startApplication().catch((error) => {
        console.error('Failed to auto-start the Unity voice experience:', error);
    });
}

if (typeof window !== 'undefined') {
    const setMutedStateHandler = setMutedState;
    window.setMutedState = (muted, options) => setMutedStateHandler(muted, options);

    Object.defineProperty(window, '__unityTestHooks', {
        value: {
            isAppReady: () => appStarted,
            getChatHistory: () => chatHistory.map((entry) => ({ ...entry })),
            getCurrentHeroImage: () => getImageUrl(),
            setHeroImage: (dataUrl) => updateHeroImage(dataUrl),
            sendUserInput: async (input) => {
                if (typeof input !== 'string' || !input.trim()) {
                    return { error: new Error('Input must be a non-empty string.') };
                }

                if (!appStarted) {
                    await startApplication();
                }

                return getAIResponse(input.trim());
            }
        },
        configurable: true,
        enumerable: false
    });
}

window.addEventListener('talk-to-unity:launch', () => {
    startApplication();
});

// NOTE: removed the duplicate 'talk-to-unity:launch' listener that was previously included.

async function ensureMicPermission() {
    if (localStorage.getItem('micPermission') === 'granted') {
        hasMicPermission = true;
        return true;
    }

    const permission = await requestMicPermission();
    if (permission) {
        hasMicPermission = true;
        updateMuteIndicator();
    }

    return permission;
}
