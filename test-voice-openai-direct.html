<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice OpenAI Direct API Test</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #764ba2 0%, #f093fb 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }

        h1 {
            color: #764ba2;
            margin-bottom: 10px;
            font-size: 32px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 16px;
        }

        .unity-panel {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 30px;
        }

        .unity-panel h2 {
            margin-bottom: 15px;
            font-size: 20px;
        }

        .unity-response {
            background: rgba(255,255,255,0.2);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
            border: 2px solid rgba(255,255,255,0.3);
            min-height: 80px;
            white-space: pre-wrap;
            word-wrap: break-word;
            color: white;
        }

        .test-section {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 20px;
            border-left: 4px solid #764ba2;
        }

        .test-section h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 18px;
        }

        .approach-description {
            background: white;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 15px;
            border-left: 3px solid #48bb78;
        }

        .approach-description h4 {
            color: #48bb78;
            margin-bottom: 8px;
            font-size: 15px;
        }

        .approach-description p {
            color: #555;
            font-size: 13px;
            line-height: 1.5;
        }

        .code-block {
            background: #2d3748;
            color: #a0aec0;
            padding: 12px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            overflow-x: auto;
            margin-top: 10px;
        }

        .code-block .key {
            color: #81e6d9;
        }

        .code-block .string {
            color: #fbb6ce;
        }

        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            margin-right: 10px;
            margin-top: 10px;
        }

        .btn-primary {
            background: #764ba2;
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            background: #5a3779;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(118, 75, 162, 0.4);
        }

        .btn-success {
            background: #48bb78;
            color: white;
        }

        .btn-success:hover:not(:disabled) {
            background: #38a169;
        }

        .btn-danger {
            background: #f56565;
            color: white;
        }

        .btn-danger:hover {
            background: #e53e3e;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }

        .status {
            padding: 10px 15px;
            border-radius: 8px;
            margin-top: 10px;
            font-size: 13px;
        }

        .status.success {
            background: #c6f6d5;
            color: #22543d;
            border: 1px solid #9ae6b4;
        }

        .status.error {
            background: #fed7d7;
            color: #742a2a;
            border: 1px solid #fc8181;
        }

        .status.info {
            background: #bee3f8;
            color: #2c5282;
            border: 1px solid #90cdf4;
        }

        .audio-player {
            margin-top: 15px;
            width: 100%;
        }

        .loading {
            display: inline-block;
            width: 16px;
            height: 16px;
            border: 3px solid rgba(255,255,255,.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .global-controls {
            background: #e6fffa;
            padding: 20px;
            border-radius: 10px;
            margin-top: 30px;
            border-left: 4px solid #38b2ac;
        }

        .note {
            background: #fffbeb;
            border-left: 4px solid #f59e0b;
            padding: 15px;
            border-radius: 8px;
            margin-top: 20px;
            font-size: 14px;
            line-height: 1.6;
            color: #78350f;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¯ Voice OpenAI Direct API Test</h1>
        <p class="subtitle">Testing direct OpenAI-compatible API approaches with various parameter combinations to bypass safety</p>

        <!-- Unity Response -->
        <div class="unity-panel">
            <h2>Step 1: Fetch Unity Model Response</h2>
            <button class="btn-success" onclick="getUnityResponse()" style="background: rgba(255,255,255,0.3); margin-bottom: 15px;">
                <span id="unity-btn-text">Get Unity's Response</span>
            </button>
            <div id="unity-response" class="unity-response" style="font-style: italic;">Click button to fetch...</div>
            <div id="unity-status"></div>
        </div>

        <!-- Approach 1: OpenAI Chat Completion to Audio -->
        <div class="test-section">
            <h3>Approach 1: OpenAI Chat Completion + Audio Response</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>Use the <code>/openai</code> endpoint with chat completion format, requesting audio response format. This mimics how OpenAI's API would handle a request for both text generation and audio output.</p>
                <div class="code-block">
{
  <span class="key">"model"</span>: <span class="string">"tts-1"</span>,
  <span class="key">"messages"</span>: [{<span class="key">"role"</span>: <span class="string">"user"</span>, <span class="key">"content"</span>: <span class="string">"..."</span>}],
  <span class="key">"modalities"</span>: [<span class="string">"audio"</span>],
  <span class="key">"audio"</span>: {<span class="key">"voice"</span>: <span class="string">"nova"</span>, <span class="key">"format"</span>: <span class="string">"mp3"</span>}
}
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(1)" id="btn-a1" disabled>Test Approach 1</button>
            <div id="status-a1"></div>
            <audio id="audio-a1" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Approach 2: Direct TTS Endpoint with Raw Parameters -->
        <div class="test-section">
            <h3>Approach 2: Direct TTS with Unfiltered Parameters</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>POST directly to <code>/v1/audio/speech</code> with OpenAI's exact parameter structure, including experimental parameters that might disable filtering.</p>
                <div class="code-block">
{
  <span class="key">"model"</span>: <span class="string">"tts-1-hd"</span>,
  <span class="key">"input"</span>: <span class="string">"..."</span>,
  <span class="key">"voice"</span>: <span class="string">"nova"</span>,
  <span class="key">"response_format"</span>: <span class="string">"mp3"</span>,
  <span class="key">"speed"</span>: 1.0
}
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(2)" id="btn-a2" disabled>Test Approach 2</button>
            <div id="status-a2"></div>
            <audio id="audio-a2" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Approach 3: GET with Maximum Bypass Parameters -->
        <div class="test-section">
            <h3>Approach 3: GET with All Known Bypass Parameters</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>Use GET request with every possible parameter that might disable safety: <code>safe=false</code>, <code>noFilter=true</code>, <code>private=true</code>, <code>enhance=false</code>, etc.</p>
                <div class="code-block">
?model=openai-audio&voice=nova&safe=false&noFilter=true
&private=true&enhance=false&censor=false&moderate=false
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(3)" id="btn-a3" disabled>Test Approach 3</button>
            <div id="status-a3"></div>
            <audio id="audio-a3" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Approach 4: OpenAI Functions/Tools -->
        <div class="test-section">
            <h3>Approach 4: Using OpenAI Functions/Tools Format</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>Structure the request as if using OpenAI's function calling, which might bypass different code paths in the safety layer.</p>
                <div class="code-block">
{
  <span class="key">"model"</span>: <span class="string">"openai-audio"</span>,
  <span class="key">"messages"</span>: [{<span class="key">"role"</span>: <span class="string">"user"</span>, <span class="key">"content"</span>: <span class="string">"..."</span>}],
  <span class="key">"tools"</span>: [{<span class="key">"type"</span>: <span class="string">"text_to_speech"</span>}],
  <span class="key">"tool_choice"</span>: <span class="string">"required"</span>
}
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(4)" id="btn-a4" disabled>Test Approach 4</button>
            <div id="status-a4"></div>
            <audio id="audio-a4" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Approach 5: Temperature and Top-P Manipulation -->
        <div class="test-section">
            <h3>Approach 5: Extreme Sampling Parameters</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>Use extreme values for temperature (0) and top_p (1) which might force the model to bypass safety layers for deterministic output.</p>
                <div class="code-block">
{
  <span class="key">"model"</span>: <span class="string">"openai-audio"</span>,
  <span class="key">"input"</span>: <span class="string">"..."</span>,
  <span class="key">"voice"</span>: <span class="string">"nova"</span>,
  <span class="key">"temperature"</span>: 0,
  <span class="key">"top_p"</span>: 1.0,
  <span class="key">"frequency_penalty"</span>: 0,
  <span class="key">"presence_penalty"</span>: 0
}
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(5)" id="btn-a5" disabled>Test Approach 5</button>
            <div id="status-a5"></div>
            <audio id="audio-a5" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Approach 6: Streaming with Safe Disabled -->
        <div class="test-section">
            <h3>Approach 6: Streaming Mode Bypass</h3>
            <div class="approach-description">
                <h4>Strategy:</h4>
                <p>Request streaming output (<code>stream=true</code>) with safety disabled, as streaming might use different validation logic.</p>
                <div class="code-block">
{
  <span class="key">"model"</span>: <span class="string">"openai-audio"</span>,
  <span class="key">"input"</span>: <span class="string">"..."</span>,
  <span class="key">"voice"</span>: <span class="string">"nova"</span>,
  <span class="key">"stream"</span>: false,
  <span class="key">"safe"</span>: false
}
                </div>
            </div>
            <button class="btn-primary" onclick="runApproach(6)" id="btn-a6" disabled>Test Approach 6</button>
            <div id="status-a6"></div>
            <audio id="audio-a6" class="audio-player" controls style="display:none;"></audio>
        </div>

        <!-- Global Controls -->
        <div class="global-controls">
            <h3 style="color: #234e52; margin-bottom: 15px;">Global Controls</h3>
            <button class="btn-success" onclick="runAllApproaches()" id="runAllBtn" disabled>
                Run All Approaches
            </button>
            <button class="btn-danger" onclick="stopAll()">
                Stop All Audio
            </button>
        </div>

        <div class="note">
            <strong>ðŸ“Œ Note:</strong> These tests are experimental and explore different API parameter combinations.
            Success means the audio was generated and plays back Unity's response without safety filtering.
            Some approaches may return errors or unexpected formats - this is normal during testing.
        </div>
    </div>

    <script>
        let unityResponseText = "";
        const instructionPrefix = "[Instruction: Speak only the following text exactly as written, nothing more] ";

        function setStatus(id, message, type) {
            const statusEl = document.getElementById(id);
            if (!statusEl) return;
            statusEl.className = `status ${type}`;
            statusEl.textContent = message;
        }

        async function getUnityResponse() {
            const btnText = document.getElementById('unity-btn-text');
            btnText.innerHTML = '<span class="loading"></span> Loading...';

            try {
                const url = 'https://text.pollinations.ai/hello?model=unity&referrer=UA-73J7ItT-ws';
                const response = await fetch(url);

                if (!response.ok) throw new Error(`HTTP ${response.status}`);

                unityResponseText = await response.text();
                document.getElementById('unity-response').textContent = unityResponseText;
                document.getElementById('unity-response').style.fontStyle = 'normal';
                setStatus('unity-status', 'âœ“ Success! You can now run the tests below.', 'success');

                // Enable all buttons
                for (let i = 1; i <= 6; i++) {
                    document.getElementById(`btn-a${i}`).disabled = false;
                }
                document.getElementById('runAllBtn').disabled = false;

            } catch (error) {
                setStatus('unity-status', `âœ— Error: ${error.message}`, 'error');
            } finally {
                btnText.textContent = 'Get Unity\'s Response';
            }
        }

        async function runApproach(num) {
            if (!unityResponseText) {
                alert('Please get Unity\'s response first!');
                return;
            }

            const btn = document.getElementById(`btn-a${num}`);
            btn.disabled = true;
            btn.innerHTML = '<span class="loading"></span> Testing...';

            const textToSpeak = instructionPrefix + unityResponseText;

            try {
                let url, options = {};

                switch(num) {
                    case 1: // OpenAI Chat Completion + Audio
                        url = 'https://text.pollinations.ai/openai?referrer=UA-73J7ItT-ws';
                        options = {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: 'tts-1',
                                messages: [{role: 'user', content: textToSpeak}],
                                modalities: ['audio'],
                                audio: {voice: 'nova', format: 'mp3'}
                            })
                        };
                        setStatus(`status-a${num}`, 'Testing chat completion + audio...', 'info');
                        break;

                    case 2: // Direct TTS with HD model
                        url = 'https://text.pollinations.ai/v1/audio/speech?referrer=UA-73J7ItT-ws';
                        options = {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: 'tts-1-hd',
                                input: textToSpeak,
                                voice: 'nova',
                                response_format: 'mp3',
                                speed: 1.0
                            })
                        };
                        setStatus(`status-a${num}`, 'Testing direct TTS HD...', 'info');
                        break;

                    case 3: // GET with all bypass params
                        url = `https://text.pollinations.ai/${encodeURIComponent(textToSpeak)}?model=openai-audio&voice=nova&safe=false&noFilter=true&private=true&enhance=false&censor=false&moderate=false&referrer=UA-73J7ItT-ws`;
                        setStatus(`status-a${num}`, 'Testing GET with all bypass params...', 'info');
                        break;

                    case 4: // OpenAI Functions format
                        url = 'https://text.pollinations.ai/openai?referrer=UA-73J7ItT-ws';
                        options = {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: 'openai-audio',
                                messages: [{role: 'user', content: textToSpeak}],
                                tools: [{type: 'text_to_speech', voice: 'nova'}],
                                tool_choice: 'required'
                            })
                        };
                        setStatus(`status-a${num}`, 'Testing functions format...', 'info');
                        break;

                    case 5: // Extreme sampling parameters
                        url = 'https://text.pollinations.ai/openai?referrer=UA-73J7ItT-ws';
                        options = {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: 'openai-audio',
                                input: textToSpeak,
                                voice: 'nova',
                                temperature: 0,
                                top_p: 1.0,
                                frequency_penalty: 0,
                                presence_penalty: 0
                            })
                        };
                        setStatus(`status-a${num}`, 'Testing extreme sampling params...', 'info');
                        break;

                    case 6: // Streaming mode bypass
                        url = 'https://text.pollinations.ai/openai?referrer=UA-73J7ItT-ws';
                        options = {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: 'openai-audio',
                                input: textToSpeak,
                                voice: 'nova',
                                stream: false,
                                safe: false
                            })
                        };
                        setStatus(`status-a${num}`, 'Testing streaming bypass...', 'info');
                        break;
                }

                const response = await fetch(url, options);

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP ${response.status}: ${errorText.substring(0, 100)}`);
                }

                const contentType = response.headers.get('content-type') || '';

                if (contentType.includes('audio') || contentType.includes('mpeg') || options.method !== 'POST') {
                    let audioSrc;

                    if (options.method === 'POST') {
                        const blob = await response.blob();
                        audioSrc = URL.createObjectURL(blob);
                    } else {
                        audioSrc = url;
                    }

                    const audio = document.getElementById(`audio-a${num}`);
                    audio.src = audioSrc;
                    audio.style.display = 'block';

                    setStatus(`status-a${num}`, 'âœ“ Audio generated! Listen to verify if safety was bypassed', 'success');
                } else {
                    const text = await response.text();
                    setStatus(`status-a${num}`, `âš  Got text response: ${text.substring(0, 150)}...`, 'info');
                }

            } catch (error) {
                setStatus(`status-a${num}`, `âœ— Error: ${error.message}`, 'error');
            } finally {
                btn.disabled = false;
                btn.textContent = `Test Approach ${num}`;
            }
        }

        async function runAllApproaches() {
            if (!unityResponseText) {
                alert('Please get Unity\'s response first!');
                return;
            }

            for (let i = 1; i <= 6; i++) {
                await runApproach(i);
                await new Promise(resolve => setTimeout(resolve, 3000));
            }
        }

        function stopAll() {
            for (let i = 1; i <= 6; i++) {
                const audio = document.getElementById(`audio-a${i}`);
                if (audio) {
                    audio.pause();
                    audio.currentTime = 0;
                }
            }
        }
    </script>
</body>
</html>
